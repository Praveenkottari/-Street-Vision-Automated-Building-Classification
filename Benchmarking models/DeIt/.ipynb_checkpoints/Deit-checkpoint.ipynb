{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e176d91-0498-4894-a3e7-b8a720009921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from transformers import DeiTForImageClassificationWithTeacher\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Paths and parameters\n",
    "data_dir = 'path_to_your_dataset'  # Your dataset path (5 subfolder classes)\n",
    "run_folder = 'results/run1'        # Results folder (run1, run2,... etc.)\n",
    "batch_size = 16\n",
    "num_epochs = 50  # Max epochs\n",
    "patience = 5     # Early stopping patience\n",
    "image_size = 224  # Input size for DeiT and ResNet\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Ensure run_folder exists\n",
    "if not os.path.exists(run_folder):\n",
    "    os.makedirs(run_folder)\n",
    "\n",
    "# Transformations: Random crop for training, Resize for validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "dataset = datasets.ImageFolder(root=data_dir)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_transform\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the teacher model (ResNet)\n",
    "teacher_model = models.resnet50(pretrained=True)\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 5)  # Assuming 5 classes\n",
    "teacher_model = teacher_model.to(device)\n",
    "teacher_model.eval()  # Teacher should be in evaluation mode\n",
    "\n",
    "# Define the DeiT model with knowledge distillation\n",
    "model = DeiTForImageClassificationWithTeacher.from_pretrained(\n",
    "    'facebook/deit-base-distilled-patch16-224', num_labels=5)\n",
    "model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Track training history\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# Early stopping initialization\n",
    "early_stop = False\n",
    "\n",
    "# Training loop with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    if early_stop:\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training phase\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Get teacher model's logits (distillation step)\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher_model(images)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, teacher_logits=teacher_logits).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_acc_history.append(train_acc)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_loss_history.append(val_loss)\n",
    "    val_acc_history.append(val_acc)\n",
    "\n",
    "    # Print metrics for this epoch\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        # Save the best model weights\n",
    "        torch.save(model.state_dict(), os.path.join(run_folder, 'best_model_weights.pth'))\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            early_stop = True\n",
    "\n",
    "    # Confusion matrix for validation set\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix (Epoch {epoch + 1})')\n",
    "    plt.savefig(os.path.join(run_folder, f'confusion_matrix_epoch_{epoch + 1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save final model weights (after training completes or early stops)\n",
    "model_save_path = os.path.join(run_folder, 'final_model_weights.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Final model weights saved to {model_save_path}')\n",
    "\n",
    "# Plot accuracy and loss graphs\n",
    "plt.figure()\n",
    "plt.plot(train_acc_history, label='Train Accuracy')\n",
    "plt.plot(val_acc_history, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(run_folder, 'accuracy_graph.png'))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss_history, label='Train Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(run_folder, 'loss_graph.png'))\n",
    "plt.close()\n",
    "\n",
    "print(f'Accuracy and loss graphs saved to {run_folder}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
